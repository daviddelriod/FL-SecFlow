{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of Secure Multiparty Computation Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it work?\n",
    "It works like this: your device downloads the current model, improves it by learning from data on your phone, and then summarizes the changes as a small focused update. Only this update to the model is sent to the cloud, using encrypted communication, where it is immediately averaged with other user updates to improve the shared model. All the training data remains on your device, and no individual updates are stored in the cloud.\n",
    "- https://ai.googleblog.com/2017/04/federated-learning-collaborative.html\n",
    "- https://www.youtube.com/watch?v=89BGjQYA0uE Desde el 13:50 Hasta 19:26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi,\n",
    "You recently answered me in the OpenFL githhub with 3 examples from your repos. I want to connect with you as I see your profile very interesting and with great knowledge about FL. I would like to connect with you as I am developing my university thesis and I think I could learn a lot from you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Clima Norte\\anaconda3\\envs\\TFG-FL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import torchvision\n",
    "#import cv2\n",
    "import tqdm as tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import openfl.native as fx\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models,datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = 'api'\n",
    "cert_dir = 'cert'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = '50051'\n",
    "\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port, \n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['150', '150', '1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federation.target_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env_one': {'shard_info': node_info {\n",
       "    name: \"env_one\"\n",
       "  }\n",
       "  shard_description: \"Chest X-ray dataset, shard number 1 out of 2\"\n",
       "  sample_shape: \"150\"\n",
       "  sample_shape: \"150\"\n",
       "  sample_shape: \"1\"\n",
       "  target_shape: \"150\"\n",
       "  target_shape: \"150\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2023-03-19 13:51:19',\n",
       "  'current_time': '2023-03-19 13:52:06',\n",
       "  'valid_duration': seconds: 120,\n",
       "  'experiment_name': 'ExperimentName Mock'},\n",
       " 'env_two': {'shard_info': node_info {\n",
       "    name: \"env_two\"\n",
       "  }\n",
       "  shard_description: \"Chest X-ray dataset, shard number 2 out of 2\"\n",
       "  sample_shape: \"150\"\n",
       "  sample_shape: \"150\"\n",
       "  sample_shape: \"1\"\n",
       "  target_shape: \"150\"\n",
       "  target_shape: \"150\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2023-03-19 13:51:23',\n",
       "  'current_time': '2023-03-19 13:52:06',\n",
       "  'valid_duration': seconds: 120,\n",
       "  'experiment_name': 'ExperimentName Mock'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 1)\n",
      "(150, 150, 1)\n"
     ]
    }
   ],
   "source": [
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=2)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "print(sample.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedDataset(Dataset):\n",
    "    \"\"\"Image Person ReID Dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, transform=None, target_transform=None):\n",
    "        \"\"\"Initialize Dataset.\"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Length of dataset.\"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.dataset[index]\n",
    "        label = self.target_transform(label) if self.target_transform else label\n",
    "        img = self.transform(img) if self.transform else img\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(DataInterface):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "        \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        \n",
    "        self.train_set = TransformedDataset(\n",
    "            self._shard_descriptor.get_dataset('train'),\n",
    "            transform=None\n",
    "        )\n",
    "        self.valid_set = TransformedDataset(\n",
    "            self._shard_descriptor.get_dataset('val'),\n",
    "            transform=None\n",
    "        )\n",
    "        \n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        generator=torch.Generator()\n",
    "        generator.manual_seed(0)\n",
    "        return DataLoader(\n",
    "            self.train_set, batch_size=self.kwargs['train_bs'], shuffle=True, generator=generator\n",
    "            )\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(self.valid_set, batch_size=self.kwargs['valid_bs'])\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = ChestXrayDataset(train_bs=32, valid_bs=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Clima Norte\\anaconda3\\envs\\TFG-FL\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "c:\\Users\\Clima Norte\\anaconda3\\envs\\TFG-FL\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        torch.manual_seed(0)\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Load pretrained DenseNet121 model\n",
    "        model_net = models.densenet121(pretrained=True)\n",
    "\n",
    "        # Freeze all parameters\n",
    "        for param in model_net.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Replace the last layer\n",
    "        model_net.classifier = nn.Sequential(OrderedDict([\n",
    "            ('fcl1', nn.Linear(1024, 256)),\n",
    "            ('dp1', nn.Dropout(0.3)),\n",
    "            ('r1', nn.ReLU()),\n",
    "            ('fcl2', nn.Linear(256, 32)),\n",
    "            ('dp2', nn.Dropout(0.3)),\n",
    "            ('r2', nn.ReLU()),\n",
    "            ('fcl3', nn.Linear(32, 2)),\n",
    "            ('out', nn.LogSoftmax(dim=1)),\n",
    "        ]))\n",
    "\n",
    "        self.model = model_net\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "model_net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "for param in model_net.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "'''\n",
    "FEDPROX\n",
    "'''        \n",
    "#from openfl.utilities.optimizers.torch import FedProxAdam        \n",
    "#optimizer = FedProxAdam(params_to_update, lr=1e-4, mu=0.01)\n",
    "\n",
    "'''\n",
    "ORIGINALE\n",
    "'''\n",
    "optimizer = optim.Adadelta(params_to_update, lr = 0.05)\n",
    "\n",
    "#optimizer = optim.AdamW(params_to_update, lr=0.001, weight_decay=0.02)\n",
    "#optimizer = optim.SGD(params_to_update, lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "#scheduler\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "def binary_cross_entropy(output, target):\n",
    "    \"\"\"Cross-entropy metric\n",
    "    \"\"\"\n",
    "    #return F.cross_entropy(input=output,target=target)\n",
    "    #return F.binary_cross_entropy_with_logits(input=output,target=target)\n",
    "    criterion = nn.NLLLoss()\n",
    "    loss = criterion(output, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "model_interface = ModelInterface(model=model_net, optimizer=optimizer, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_interface = TaskInterface()\n",
    "\n",
    "# The Interactive API supports registering functions definied in main module or imported.\n",
    "def function_defined_in_notebook(some_parameter):\n",
    "    print(f'Also I accept a parameter and it is {some_parameter}')\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@task_interface.add_kwargs(**{'some_parameter': 42})\n",
    "@task_interface.register_fl_task(model='net_model', data_loader='train_loader',\n",
    "                     device='device', optimizer='optimizer') \n",
    "#@task_interface.set_aggregation_function(FedCurvWeightedAverage())\n",
    "def train(net_model, train_loader, optimizer, device, loss_fn=binary_cross_entropy, some_parameter=None):\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor = 0.75, patience = 4)\n",
    "    torch.manual_seed(0)\n",
    "    device='cpu'\n",
    "    function_defined_in_notebook(some_parameter)\n",
    "    \n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    net_model.train()\n",
    "    net_model.to(device)\n",
    "    train_loss_min = 30\n",
    "    train_loss = 0.0\n",
    "    epochs = 8\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if epoch == 8 // 2: #SE PODRIA CALCAR EL TRAIN DE KAGGLE Y LUEGO DEJAR LA TASK DE VALIDAR IGUAL, SOLO PARA QUE CARGUE LOS STATES MIRANDO EL VAL_LOSS\n",
    "            net_model.load_state_dict(torch.load('saved_state.pth'))\n",
    "            for param in net_model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        if scheduler != None:\n",
    "            scheduler.step(train_loss)\n",
    "        \n",
    "        net_model.train()\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = net_model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "            train_loss += loss.item() * data.size(0)\n",
    "        if train_loss <= train_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(train_loss_min, train_loss))\n",
    "            torch.save(net_model.state_dict(), 'saved_state.pth')\n",
    "            train_loss_min = train_loss\n",
    "    return {'train_loss': train_loss,}\n",
    "\n",
    "@task_interface.register_fl_task(model='net_model', data_loader='val_loader', device='device')     \n",
    "def validate(net_model, val_loader, device):\n",
    "    torch.manual_seed(0)\n",
    "    device = torch.device('cpu')\n",
    "    val_loader = tqdm.tqdm(val_loader, desc = \"validate\")\n",
    "    net_model.eval()\n",
    "    metrics = {'Accuracy':[], 'Precision':[], 'Recall':[], 'F1-Score':[]}\n",
    "    number_correct, number_data = 0, 0\n",
    "    true_labels, predicted_labels = [], []\n",
    "\n",
    "    for data, target in val_loader:\n",
    "        output = net_model(data)\n",
    "        _, pred = torch.max(output, 1) \n",
    "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) \n",
    "        number_correct += sum(correct)\n",
    "        number_data += correct.shape[0]\n",
    "        true_labels.extend(target.cpu().numpy())\n",
    "        predicted_labels.extend(pred.cpu().numpy())\n",
    "\n",
    "    train_loss = train_loss / len(val_loader)\n",
    "    valid_loss = valid_loss / len(val_loader)\n",
    "    accuracy = (100 * number_correct / number_data)\n",
    "    precision, recall, f1_score, support = precision_recall_fscore_support(\n",
    "        true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    metrics['Accuracy'].append(accuracy)\n",
    "    metrics['Precision'].append(precision*100)\n",
    "    metrics['Recall'].append(recall*100)\n",
    "    metrics['F1-Score'].append(f1_score*100)  \n",
    "              \n",
    "    return {'acc': np.mean(metrics['Accuracy']),}"
    "    return metrics['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'ChestXray_EPOCHS8_ROUND10_CNN'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to define our dataset and model to perform federated learning on. The dataset should be composed of a numpy arrayWe start with a simple fully connected model that is trained on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[13:52:33] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Building <span style=\"color: #800000; text-decoration-color: #800000\">🡆</span> Object <span style=\"color: #800000; text-decoration-color: #800000\">CloudpickleSerializer</span> from <span style=\"color: #800000; text-decoration-color: #800000\">openfl.plugins.interface_serializer.cloudpickle_serializer</span> Module.                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plan.py:173</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[13:52:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Building \u001b[31m🡆\u001b[0m Object \u001b[31mCloudpickleSerializer\u001b[0m from \u001b[31mopenfl.plugins.interface_serializer.cloudpickle_serializer\u001b[0m Module.                  \u001b[2mplan.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m173\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Building <span style=\"color: #800000; text-decoration-color: #800000\">🡆</span> Object <span style=\"color: #800000; text-decoration-color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000; text-decoration-color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plan.py:173</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Building \u001b[31m🡆\u001b[0m Object \u001b[31mFrameworkAdapterPlugin\u001b[0m from \u001b[31mopenfl.plugins.frameworks_adapters.pytorch_adapter\u001b[0m Module.                         \u001b[2mplan.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m173\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Clima Norte\\anaconda3\\envs\\TFG-FL\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[13:52:35] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Starting experiment!                                                                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py:245</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[13:52:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting experiment!                                                                                                       \u001b[2mexperiment.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m245\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> FL-Plan hash is <span style=\"color: #000080; text-decoration-color: #000080\">a1d5bd48796b13f7452db6f4304dac1b82c34e0b0274b0e60d5c15f78a4161b199d8fcb5f57bf0c149ac6c8499648d98</span>                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plan.py:236</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m FL-Plan hash is \u001b[34ma1d5bd48796b13f7452db6f4304dac1b82c34e0b0274b0e60d5c15f78a4161b199d8fcb5f57bf0c149ac6c8499648d98\u001b[0m                 \u001b[2mplan.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m236\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[13:52:36] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> FL-Plan hash is <span style=\"color: #000080; text-decoration-color: #000080\">a1d5bd48796b13f7452db6f4304dac1b82c34e0b0274b0e60d5c15f78a4161b199d8fcb5f57bf0c149ac6c8499648d98</span>                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plan.py:236</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[13:52:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m FL-Plan hash is \u001b[34ma1d5bd48796b13f7452db6f4304dac1b82c34e0b0274b0e60d5c15f78a4161b199d8fcb5f57bf0c149ac6c8499648d98\u001b[0m                 \u001b[2mplan.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m236\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Building <span style=\"color: #800000; text-decoration-color: #800000\">🡆</span> Object <span style=\"color: #800000; text-decoration-color: #800000\">CoreTaskRunner</span> from <span style=\"color: #800000; text-decoration-color: #800000\">openfl.federated.task.task_runner</span> Module.                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plan.py:173</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Building \u001b[31m🡆\u001b[0m Object \u001b[31mCoreTaskRunner\u001b[0m from \u001b[31mopenfl.federated.task.task_runner\u001b[0m Module.                                                  \u001b[2mplan.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m173\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Building <span style=\"color: #800000; text-decoration-color: #800000\">🡆</span> Object <span style=\"color: #800000; text-decoration-color: #800000\">FrameworkAdapterPlugin</span> from <span style=\"color: #800000; text-decoration-color: #800000\">openfl.plugins.frameworks_adapters.pytorch_adapter</span> Module.                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">plan.py:173</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Building \u001b[31m🡆\u001b[0m Object \u001b[31mFrameworkAdapterPlugin\u001b[0m from \u001b[31mopenfl.plugins.frameworks_adapters.pytorch_adapter\u001b[0m Module.                         \u001b[2mplan.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m173\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py:172</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       \u001b[2mutils.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m172\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py:172</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m tried to remove tensor: __opt_state_needed not present in the tensor dict                                                       \u001b[2mutils.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m172\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> SetNewExperiment                                                                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">director_client.py:209</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m SetNewExperiment                                                                                                      \u001b[2mdirector_client.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m209\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[13:52:39] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Experiment was submitted to the director!                                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py:259</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[13:52:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Experiment was submitted to the director!                                                                                  \u001b[2mexperiment.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m259\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(\n",
    "    model_provider=model_interface, \n",
    "    task_keeper=task_interface,\n",
    "    data_loader=fed_dataset,\n",
    "    rounds_to_train=5,\n",
    "    opt_treatment='CONTINUE_GLOBAL'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8788\\2846161417.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# fl_experiment.restore_experiment_state(model_interface)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfl_experiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensorboard_logs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Clima Norte\\anaconda3\\envs\\TFG-FL\\lib\\site-packages\\openfl\\interface\\interactive_api\\experiment.py\u001b[0m in \u001b[0;36mstream_metrics\u001b[1;34m(self, tensorboard_logs)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_experiment_submitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmetric_message_dict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfederation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdir_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m             self.logger.metric(\n\u001b[0;32m    145\u001b[0m                 \u001b[1;34mf'Round {metric_message_dict[\"round\"]}, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Clima Norte\\anaconda3\\envs\\TFG-FL\\lib\\site-packages\\openfl\\transport\\grpc\\director_client.py\u001b[0m in \u001b[0;36mstream_metrics\u001b[1;34m(self, experiment_name)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;34m\"\"\"Stream metrics RPC.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirector_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetMetricStreamRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmetric_message\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetMetricStream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m             yield {\n\u001b[0;32m    279\u001b[0m                 \u001b[1;34m'metric_origin'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetric_message\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetric_origin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Clima Norte\\anaconda3\\envs\\TFG-FL\\lib\\site-packages\\grpc\\_channel.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Clima Norte\\anaconda3\\envs\\TFG-FL\\lib\\site-packages\\grpc\\_channel.py\u001b[0m in \u001b[0;36m_next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    815\u001b[0m                          self._state.code is not None))\n\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m             \u001b[0m_common\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_response_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Clima Norte\\anaconda3\\envs\\TFG-FL\\lib\\site-packages\\grpc\\_common.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(wait_fn, wait_complete_fn, timeout, spin_cb)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mwait_complete_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0m_wait_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAXIMUM_WAIT_TIMEOUT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspin_cb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Clima Norte\\anaconda3\\envs\\TFG-FL\\lib\\site-packages\\grpc\\_common.py\u001b[0m in \u001b[0;36m_wait_once\u001b[1;34m(wait_fn, timeout, spin_cb)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wait_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspin_cb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mwait_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspin_cb\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mspin_cb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Clima Norte\\anaconda3\\envs\\TFG-FL\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# If user want to stop IPython session, then reconnect and check how experiment is going\n",
    "# fl_experiment.restore_experiment_state(model_interface)\n",
    "\n",
    "fl_experiment.stream_metrics(tensorboard_logs=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d69f63ea15b6bb008b8d31206bc050e6263a4c89b8d4a8f3080901fb7da99ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
